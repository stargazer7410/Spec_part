
# ğŸ§  Specialty_Partners Project Summary

## ğŸ”§ Purpose
Automate and orchestrate data processing using **Azure Data Factory (ADF)** and **Databricks**, enabling dynamic job execution, structured logging, and centralized monitoring.

## ğŸš€ Workflow Overview
1. **ADF** monitors a folder in **Azure Data Lake Storage (ADLS)**.
2. On file drop, ADF triggers a **Databricks job**, passing a `job_name`.
3. **Databricks** executes `main.py`, which:
   - Loads job parameters from config files.
   - Dynamically imports and runs the corresponding job module.
   - Executes an associated SQL script if available.
   - Logs events locally and to **Azure Monitor**.

## ğŸ“ Folder Structure
```
Specialty_Partners
â”‚
â”œâ”€â”€ main.py
â”‚
â”œâ”€â”€ config
â”‚   â”œâ”€â”€ config.json
â”‚   â””â”€â”€ job_params.json
â”‚
â”œâ”€â”€ python
â”‚   â”œâ”€â”€ jobs
â”‚   â”‚   â””â”€â”€ thyme-care.py
â”‚   â”‚
â”‚   â””â”€â”€ utils
â”‚       â”œâ”€â”€ logger_setup.py
â”‚       â”œâ”€â”€ param_loader.py
â”‚       â”œâ”€â”€ error_handler.py
â”‚       â”œâ”€â”€ sql_runner.py
â”‚       â”œâ”€â”€ constants.py
â”‚       â”œâ”€â”€ log_manager.py
â”‚       â””â”€â”€ azure_monitor.py
â”‚
â”œâ”€â”€ sql
â”‚   â””â”€â”€ thyme-care.sql
```

## âœ… Key Features
- **Config-driven architecture**: Externalized paths and job mappings.
- **Dynamic job execution**: Uses `importlib` for modular job loading.
- **Structured logging**: Dual logging to local files and Azure Monitor.
- **Centralized error handling**: Managed via `ErrorHandler` class.
- **Reusable utilities**: Modular components for logging, SQL, and parameter handling.
- **Scalable design**: Easily extendable with new jobs and configurations.

## ğŸ§ª Testing & Validation
- Verified integration of all modules and functions.
- Simulated end-to-end job execution:
  - Job name validation
  - Parameter loading
  - Job module execution
  - SQL script detection and execution
  - Logging and Azure Monitor event tracking

## ğŸ“¦ Download
Full project available: `ğŸ“ Specialty_Partners.zip`
